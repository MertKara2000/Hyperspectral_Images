{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SpectralNET Exploring Spatial Spectral Wavelet CNN for Hyper Spectral Image Classification\n",
    "\n",
    "**Authors:** Tanmay CHAKRABORTY and Utkarsh TREHAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "executionInfo": {
     "elapsed": 5572,
     "status": "ok",
     "timestamp": 1602478409232,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "r9imWZNCMoOM",
    "outputId": "e6ddc3e2-53c3-4e29-ceb6-5b303ac0b75b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spectral in c:\\users\\monster\\anaconda3\\envs\\image\\lib\\site-packages (0.22.4)\n",
      "Requirement already satisfied: numpy in c:\\users\\monster\\anaconda3\\envs\\image\\lib\\site-packages (from spectral) (1.21.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\monster\\anaconda3\\envs\\image\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\monster\\anaconda3\\envs\\image\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\monster\\anaconda3\\envs\\image\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\monster\\anaconda3\\envs\\image\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\monster\\anaconda3\\envs\\image\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\monster\\anaconda3\\envs\\image\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\monster\\anaconda3\\envs\\image\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\monster\\anaconda3\\envs\\image\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\monster\\anaconda3\\envs\\image\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\monster\\anaconda3\\envs\\image\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\monster\\anaconda3\\envs\\image\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\monster\\anaconda3\\envs\\image\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.layers import Conv2D, Conv3D, Flatten, Dense, Reshape, BatchNormalization\n",
    "from keras.layers import Dropout, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as Kb\n",
    "from keras.layers import Lambda\n",
    "from keras.layers import Activation\n",
    "from keras.layers.merge import add, concatenate\n",
    "from keras.layers import AveragePooling2D\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, cohen_kappa_score\n",
    " \n",
    "from sklearn.decomposition import FactorAnalysis\n",
    "from sklearn.decomposition import PCA\n",
    "from operator import truediv\n",
    " \n",
    "from plotly.offline import init_notebook_mode\n",
    " \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sio\n",
    "import os\n",
    "!pip install spectral\n",
    "import spectral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 5565,
     "status": "ok",
     "timestamp": 1602478409233,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "HC83Bv1IPQfc"
   },
   "outputs": [],
   "source": [
    "def applyFA(X, numComponents=75):\n",
    "    newX = np.reshape(X, (-1, X.shape[2]))\n",
    "    fa = FactorAnalysis(n_components=numComponents, random_state=0)\n",
    "    newX = fa.fit_transform(newX)\n",
    "    newX = np.reshape(newX, (X.shape[0],X.shape[1], numComponents))\n",
    "    return newX, fa\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 5559,
     "status": "ok",
     "timestamp": 1602478409234,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "UGivdxXN1pCh"
   },
   "outputs": [],
   "source": [
    "# def applyPCA(X, numComponents=75):\n",
    "#     newX = np.reshape(X, (-1, X.shape[2]))\n",
    "#     pca = PCA(n_components=numComponents, whiten=True)\n",
    "#     newX = pca.fit_transform(newX)\n",
    "#     newX = np.reshape(newX, (X.shape[0],X.shape[1], numComponents))\n",
    "#     return newX, pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 5555,
     "status": "ok",
     "timestamp": 1602478409235,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "jEBfhIyVNHRQ"
   },
   "outputs": [],
   "source": [
    "## GLOBAL VARIABLES\n",
    "dataset = 'SA'\n",
    "test_ratio = 0.9\n",
    "windowSize = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 5550,
     "status": "ok",
     "timestamp": 1602478409236,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "7wXNSkhfM3gs"
   },
   "outputs": [],
   "source": [
    "def loadData(name):\n",
    "    data_path = os.path.join(os.getcwd(),'data')\n",
    "    if name == 'IP':\n",
    "        data = sio.loadmat(os.path.join(data_path, 'Indian_pines_corrected.mat'))['indian_pines_corrected']\n",
    "        labels = sio.loadmat(os.path.join(data_path, 'Indian_pines_gt.mat'))['indian_pines_gt']\n",
    "    elif name == 'SA':\n",
    "        data = sio.loadmat(os.path.join(data_path, 'Salinas_corrected.mat'))['salinas_corrected']\n",
    "        labels = sio.loadmat(os.path.join(data_path, 'Salinas_gt.mat'))['salinas_gt']\n",
    "    elif name == 'PU':\n",
    "        data = sio.loadmat(os.path.join(data_path, 'PaviaU.mat'))['paviaU']\n",
    "        labels = sio.loadmat(os.path.join(data_path, 'PaviaU_gt.mat'))['paviaU_gt']\n",
    "    \n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 5545,
     "status": "ok",
     "timestamp": 1602478409237,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "iaIzfkQ3NDvS"
   },
   "outputs": [],
   "source": [
    "def splitTrainTestSet(X, y, testRatio, randomState=345):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=testRatio, random_state=randomState,\n",
    "                                                        stratify=y)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 5538,
     "status": "ok",
     "timestamp": 1602478409237,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "M0he4FtONMU-"
   },
   "outputs": [],
   "source": [
    "def padWithZeros(X, margin=2):\n",
    "    newX = np.zeros((X.shape[0] + 2 * margin, X.shape[1] + 2* margin, X.shape[2]))\n",
    "    x_offset = margin\n",
    "    y_offset = margin\n",
    "    newX[x_offset:X.shape[0] + x_offset, y_offset:X.shape[1] + y_offset, :] = X\n",
    "    return newX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 5533,
     "status": "ok",
     "timestamp": 1602478409238,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "l0wsTkhNNO04"
   },
   "outputs": [],
   "source": [
    "def createImageCubes(X, y, windowSize=8, removeZeroLabels = True):\n",
    "    margin = int((windowSize) / 2)\n",
    "    zeroPaddedX = padWithZeros(X, margin=margin)\n",
    "    # split patches\n",
    "    patchesData = np.zeros((X.shape[0] * X.shape[1], windowSize, windowSize, X.shape[2]))\n",
    "    patchesLabels = np.zeros((X.shape[0] * X.shape[1]))\n",
    "    patchIndex = 0\n",
    "    for r in range(margin, zeroPaddedX.shape[0] - margin):\n",
    "        for c in range(margin, zeroPaddedX.shape[1] - margin):\n",
    "            patch = zeroPaddedX[r - margin:r + margin , c - margin:c + margin ]   \n",
    "            patchesData[patchIndex, :, :, :] = patch\n",
    "            patchesLabels[patchIndex] = y[r-margin, c-margin]\n",
    "            patchIndex = patchIndex + 1\n",
    "    if removeZeroLabels:\n",
    "        patchesData = patchesData[patchesLabels>0,:,:,:]\n",
    "        patchesLabels = patchesLabels[patchesLabels>0]\n",
    "        patchesLabels -= 1\n",
    "    return patchesData, patchesLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 5525,
     "status": "ok",
     "timestamp": 1602478409238,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "cnneGlFFNRVo",
    "outputId": "3b00138d-9d02-4b14-f6e2-2b1dc9ad8aeb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((512, 217, 204), (512, 217))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = loadData(dataset)\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 5518,
     "status": "ok",
     "timestamp": 1602478409239,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "TOGl1BmWNdyv"
   },
   "outputs": [],
   "source": [
    "K = X.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 30165,
     "status": "ok",
     "timestamp": 1602478433894,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "fTYzjiltNj8a",
    "outputId": "7bfa99db-15b8-40d1-83b2-b7d32d039c0e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 217, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K = 3 if dataset == 'IP' else 3\n",
    "X,fa = applyFA(X,numComponents=K)\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 31758,
     "status": "ok",
     "timestamp": 1602478435499,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "hiZiDsE0cN-O",
    "outputId": "acf836b7-666b-4104-c856-d4e0b1d1f84f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((54129, 24, 24, 3), (54129,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = createImageCubes(X, y, windowSize=windowSize)\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 31739,
     "status": "ok",
     "timestamp": 1602478435500,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "OMYMZxnDcSHb",
    "outputId": "8e9b4564-aff1-40e2-b081-7154c18d5d77"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5412, 24, 24, 3), (48717, 24, 24, 3), (5412,), (48717,))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain, Xtest, ytrain, ytest = splitTrainTestSet(X, y, test_ratio)\n",
    "\n",
    "Xtrain.shape, Xtest.shape, ytrain.shape, ytest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 31716,
     "status": "ok",
     "timestamp": 1602478435501,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "VBvWzipfcZDK",
    "outputId": "af402f16-e7ee-4272-c243-ae05646c8317"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5412, 24, 24, 3, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain = Xtrain.reshape(-1, windowSize, windowSize, K, 1)\n",
    "Xtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 31703,
     "status": "ok",
     "timestamp": 1602478435502,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "lxr7HMjocZvd",
    "outputId": "cb12450a-7ffc-44a2-d57b-2e42e0402ec4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5412, 16)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytrain = np_utils.to_categorical(ytrain)\n",
    "ytrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 31691,
     "status": "ok",
     "timestamp": 1602478435502,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "pAmd40PJcdog"
   },
   "outputs": [],
   "source": [
    "S1 = windowSize\n",
    "L1 = K\n",
    "output_units = 9 if (dataset == 'PU' or dataset == 'PC') else 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 31687,
     "status": "ok",
     "timestamp": 1602478435503,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "wQDctC5hdHlP"
   },
   "outputs": [],
   "source": [
    "def WaveletTransformAxisY(batch_img):\n",
    "    odd_img  = batch_img[:,0::2]\n",
    "    even_img = batch_img[:,1::2]\n",
    "    L = (odd_img + even_img) / 2.0\n",
    "    H = Kb.abs(odd_img - even_img)\n",
    "    return L, H\n",
    "\n",
    "def WaveletTransformAxisX(batch_img):\n",
    "    # transpose + fliplr\n",
    "    tmp_batch = Kb.permute_dimensions(batch_img, [0, 2, 1])[:,:,::-1]\n",
    "    _dst_L, _dst_H = WaveletTransformAxisY(tmp_batch)\n",
    "    # transpose + flipud\n",
    "    dst_L = Kb.permute_dimensions(_dst_L, [0, 2, 1])[:,::-1,...]\n",
    "    dst_H = Kb.permute_dimensions(_dst_H, [0, 2, 1])[:,::-1,...]\n",
    "    return dst_L, dst_H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 31679,
     "status": "ok",
     "timestamp": 1602478435503,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "NCAUyHZFdPfN"
   },
   "outputs": [],
   "source": [
    "def Wavelet(batch_image):\n",
    "    # make channel first image\n",
    "    batch_image = Kb.permute_dimensions(batch_image, [0, 3, 1, 2])\n",
    "    r = batch_image[:,0]\n",
    "    g = batch_image[:,1]\n",
    "    b = batch_image[:,2]\n",
    "\n",
    "    # level 1 decomposition\n",
    "    wavelet_L, wavelet_H = WaveletTransformAxisY(r)\n",
    "    r_wavelet_LL, r_wavelet_LH = WaveletTransformAxisX(wavelet_L)\n",
    "    r_wavelet_HL, r_wavelet_HH = WaveletTransformAxisX(wavelet_H)\n",
    "\n",
    "    wavelet_L, wavelet_H = WaveletTransformAxisY(g)\n",
    "    g_wavelet_LL, g_wavelet_LH = WaveletTransformAxisX(wavelet_L)\n",
    "    g_wavelet_HL, g_wavelet_HH = WaveletTransformAxisX(wavelet_H)\n",
    "\n",
    "    wavelet_L, wavelet_H = WaveletTransformAxisY(b)\n",
    "    b_wavelet_LL, b_wavelet_LH = WaveletTransformAxisX(wavelet_L)\n",
    "    b_wavelet_HL, b_wavelet_HH = WaveletTransformAxisX(wavelet_H)\n",
    "\n",
    "    wavelet_data = [r_wavelet_LL, r_wavelet_LH, r_wavelet_HL, r_wavelet_HH, \n",
    "                    g_wavelet_LL, g_wavelet_LH, g_wavelet_HL, g_wavelet_HH,\n",
    "                    b_wavelet_LL, b_wavelet_LH, b_wavelet_HL, b_wavelet_HH]\n",
    "    transform_batch = Kb.stack(wavelet_data, axis=1)\n",
    "\n",
    "    # level 2 decomposition\n",
    "    wavelet_L2, wavelet_H2 = WaveletTransformAxisY(r_wavelet_LL)\n",
    "    r_wavelet_LL2, r_wavelet_LH2 = WaveletTransformAxisX(wavelet_L2)\n",
    "    r_wavelet_HL2, r_wavelet_HH2 = WaveletTransformAxisX(wavelet_H2)\n",
    "\n",
    "    wavelet_L2, wavelet_H2 = WaveletTransformAxisY(g_wavelet_LL)\n",
    "    g_wavelet_LL2, g_wavelet_LH2 = WaveletTransformAxisX(wavelet_L2)\n",
    "    g_wavelet_HL2, g_wavelet_HH2 = WaveletTransformAxisX(wavelet_H2)\n",
    "\n",
    "    wavelet_L2, wavelet_H2 = WaveletTransformAxisY(b_wavelet_LL)\n",
    "    b_wavelet_LL2, b_wavelet_LH2 = WaveletTransformAxisX(wavelet_L2)\n",
    "    b_wavelet_HL2, b_wavelet_HH2 = WaveletTransformAxisX(wavelet_H2)\n",
    "\n",
    "\n",
    "    wavelet_data_l2 = [r_wavelet_LL2, r_wavelet_LH2, r_wavelet_HL2, r_wavelet_HH2, \n",
    "                    g_wavelet_LL2, g_wavelet_LH2, g_wavelet_HL2, g_wavelet_HH2,\n",
    "                    b_wavelet_LL2, b_wavelet_LH2, b_wavelet_HL2, b_wavelet_HH2]\n",
    "    transform_batch_l2 = Kb.stack(wavelet_data_l2, axis=1)\n",
    "\n",
    "    # level 3 decomposition\n",
    "    wavelet_L3, wavelet_H3 = WaveletTransformAxisY(r_wavelet_LL2)\n",
    "    r_wavelet_LL3, r_wavelet_LH3 = WaveletTransformAxisX(wavelet_L3)\n",
    "    r_wavelet_HL3, r_wavelet_HH3 = WaveletTransformAxisX(wavelet_H3)\n",
    "\n",
    "    wavelet_L3, wavelet_H3 = WaveletTransformAxisY(g_wavelet_LL2)\n",
    "    g_wavelet_LL3, g_wavelet_LH3 = WaveletTransformAxisX(wavelet_L3)\n",
    "    g_wavelet_HL3, g_wavelet_HH3 = WaveletTransformAxisX(wavelet_H3)\n",
    "\n",
    "    wavelet_L3, wavelet_H3 = WaveletTransformAxisY(b_wavelet_LL2)\n",
    "    b_wavelet_LL3, b_wavelet_LH3 = WaveletTransformAxisX(wavelet_L3)\n",
    "    b_wavelet_HL3, b_wavelet_HH3 = WaveletTransformAxisX(wavelet_H3)\n",
    "\n",
    "    wavelet_data_l3 = [r_wavelet_LL3, r_wavelet_LH3, r_wavelet_HL3, r_wavelet_HH3, \n",
    "                    g_wavelet_LL3, g_wavelet_LH3, g_wavelet_HL3, g_wavelet_HH3,\n",
    "                    b_wavelet_LL3, b_wavelet_LH3, b_wavelet_HL3, b_wavelet_HH3]\n",
    "    transform_batch_l3 = Kb.stack(wavelet_data_l3, axis=1)\n",
    "\n",
    "    # level 4 decomposition\n",
    "    wavelet_L4, wavelet_H4 = WaveletTransformAxisY(r_wavelet_LL3)\n",
    "    r_wavelet_LL4, r_wavelet_LH4 = WaveletTransformAxisX(wavelet_L4)\n",
    "    r_wavelet_HL4, r_wavelet_HH4 = WaveletTransformAxisX(wavelet_H4)\n",
    "\n",
    "    wavelet_L4, wavelet_H4 = WaveletTransformAxisY(g_wavelet_LL3)\n",
    "    g_wavelet_LL4, g_wavelet_LH4 = WaveletTransformAxisX(wavelet_L4)\n",
    "    g_wavelet_HL4, g_wavelet_HH4 = WaveletTransformAxisX(wavelet_H4)\n",
    "\n",
    "    wavelet_L3, wavelet_H3 = WaveletTransformAxisY(b_wavelet_LL3)\n",
    "    b_wavelet_LL4, b_wavelet_LH4 = WaveletTransformAxisX(wavelet_L4)\n",
    "    b_wavelet_HL4, b_wavelet_HH4 = WaveletTransformAxisX(wavelet_H4)\n",
    "\n",
    "\n",
    "    wavelet_data_l4 = [r_wavelet_LL4, r_wavelet_LH4, r_wavelet_HL4, r_wavelet_HH4, \n",
    "                    g_wavelet_LL4, g_wavelet_LH4, g_wavelet_HL4, g_wavelet_HH4,\n",
    "                    b_wavelet_LL4, b_wavelet_LH4, b_wavelet_HL4, b_wavelet_HH4]\n",
    "    transform_batch_l4 = Kb.stack(wavelet_data_l4, axis=1)\n",
    "\n",
    "    # print('shape before')\n",
    "    # print(transform_batch.shape)\n",
    "    # print(transform_batch_l2.shape)\n",
    "    # print(transform_batch_l3.shape)\n",
    "    # print(transform_batch_l4.shape)\n",
    "\n",
    "    decom_level_1 = Kb.permute_dimensions(transform_batch, [0, 2, 3, 1])\n",
    "    decom_level_2 = Kb.permute_dimensions(transform_batch_l2, [0, 2, 3, 1])\n",
    "    decom_level_3 = Kb.permute_dimensions(transform_batch_l3, [0, 2, 3, 1])\n",
    "    decom_level_4 = Kb.permute_dimensions(transform_batch_l4, [0, 2, 3, 1])\n",
    "    \n",
    "    # print('shape after')\n",
    "    # print(decom_level_1.shape)\n",
    "    # print(decom_level_2.shape)\n",
    "    # print(decom_level_3.shape)\n",
    "    # print(decom_level_4.shape)\n",
    "    return [decom_level_1, decom_level_2, decom_level_3, decom_level_4]\n",
    "\n",
    "\n",
    "def Wavelet_out_shape(input_shapes):\n",
    "    # print('in to shape')\n",
    "    return [tuple([None, 112, 112, 12]), tuple([None, 56, 56, 12]), \n",
    "            tuple([None, 28, 28, 12]), tuple([None, 14, 14, 12])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 31664,
     "status": "ok",
     "timestamp": 1602478435504,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "GVN-IuF7e2OB",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "2d2cbade-23cf-4833-8750-3755e381c91f",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(8, 12, 12, 12), dtype=float32, numpy=\n",
       " array([[[[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "        ...,\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(8, 6, 6, 12), dtype=float32, numpy=\n",
       " array([[[[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "        ...,\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(8, 3, 3, 12), dtype=float32, numpy=\n",
       " array([[[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(8, 2, 2, 12), dtype=float32, numpy=\n",
       " array([[[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]]],\n",
       "       dtype=float32)>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_batch = Kb.zeros(shape=(8, 24, 24, 3), dtype='float32')\n",
    "Wavelet(img_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 31657,
     "status": "ok",
     "timestamp": 1602478435506,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "5taLY_ljgFq3"
   },
   "outputs": [],
   "source": [
    "def get_wavelet_cnn_model():\n",
    " \n",
    "    input_shape =  24, 24, 3\n",
    " \n",
    "    input_ = Input(input_shape, name='the_input')\n",
    "    # wavelet = Lambda(Wavelet, name='wavelet')\n",
    "    wavelet = Lambda(Wavelet, Wavelet_out_shape, name='wavelet')\n",
    "    input_l1, input_l2, input_l3, input_l4 = wavelet(input_)\n",
    "    # print(input_l1)\n",
    "    # print(input_l2)\n",
    "    # print(input_l3)\n",
    "    # print(input_l4)\n",
    "    # level one decomposition starts\n",
    "    conv_1 = Conv2D(64, kernel_size=(3, 3), padding='same', name='conv_1')(input_l1)\n",
    "    norm_1 = BatchNormalization(name='norm_1')(conv_1)\n",
    "    relu_1 = Activation('relu', name='relu_1')(norm_1)\n",
    " \n",
    "    conv_1_2 = Conv2D(64, kernel_size=(3, 3), strides=(2, 2), padding='same', name='conv_1_2')(relu_1)\n",
    "    norm_1_2 = BatchNormalization(name='norm_1_2')(conv_1_2)\n",
    "    relu_1_2 = Activation('relu', name='relu_1_2')(norm_1_2)\n",
    " \n",
    "    # level two decomposition starts\n",
    "    conv_a = Conv2D(filters=64, kernel_size=(3, 3), padding='same', name='conv_a')(input_l2)\n",
    "    norm_a = BatchNormalization(name='norm_a')(conv_a)\n",
    "    relu_a = Activation('relu', name='relu_a')(norm_a)\n",
    " \n",
    "    # concate level one and level two decomposition\n",
    "    concate_level_2 = concatenate([relu_1_2, relu_a])\n",
    "    conv_2 = Conv2D(128, kernel_size=(3, 3), padding='same', name='conv_2')(concate_level_2)\n",
    "    norm_2 = BatchNormalization(name='norm_2')(conv_2)\n",
    "    relu_2 = Activation('relu', name='relu_2')(norm_2)\n",
    " \n",
    "    conv_2_2 = Conv2D(128, kernel_size=(3, 3), strides=(2, 2), padding='same', name='conv_2_2')(relu_2)\n",
    "    norm_2_2 = BatchNormalization(name='norm_2_2')(conv_2_2)\n",
    "    relu_2_2 = Activation('relu', name='relu_2_2')(norm_2_2)\n",
    " \n",
    "    # level three decomposition starts \n",
    "    conv_b = Conv2D(filters=64, kernel_size=(3, 3), padding='same', name='conv_b')(input_l3)\n",
    "    norm_b = BatchNormalization(name='norm_b')(conv_b)\n",
    "    relu_b = Activation('relu', name='relu_b')(norm_b)\n",
    " \n",
    "    conv_b_2 = Conv2D(128, kernel_size=(3, 3), padding='same', name='conv_b_2')(relu_b)\n",
    "    norm_b_2 = BatchNormalization(name='norm_b_2')(conv_b_2)\n",
    "    relu_b_2 = Activation('relu', name='relu_b_2')(norm_b_2)\n",
    " \n",
    "    # concate level two and level three decomposition \n",
    "    concate_level_3 = concatenate([relu_2_2, relu_b_2])\n",
    "    conv_3 = Conv2D(256, kernel_size=(3, 3), padding='same', name='conv_3')(concate_level_3)\n",
    "    norm_3 = BatchNormalization(name='nomr_3')(conv_3)\n",
    "    relu_3 = Activation('relu', name='relu_3')(norm_3)\n",
    " \n",
    "    conv_3_2 = Conv2D(256, kernel_size=(3, 3), strides=(2, 2), padding='same', name='conv_3_2')(relu_3)\n",
    "    norm_3_2 = BatchNormalization(name='norm_3_2')(conv_3_2)\n",
    "    relu_3_2 = Activation('relu', name='relu_3_2')(norm_3_2)\n",
    " \n",
    "    # level four decomposition start\n",
    "    conv_c = Conv2D(64, kernel_size=(3, 3), padding='same', name='conv_c')(input_l4)\n",
    "    norm_c = BatchNormalization(name='norm_c')(conv_c)\n",
    "    relu_c = Activation('relu', name='relu_c')(norm_c)\n",
    " \n",
    "    conv_c_2 = Conv2D(256, kernel_size=(3, 3), padding='same', name='conv_c_2')(relu_c)\n",
    "    norm_c_2 = BatchNormalization(name='norm_c_2')(conv_c_2)\n",
    "    relu_c_2 = Activation('relu', name='relu_c_2')(norm_c_2)\n",
    " \n",
    "    conv_c_3 = Conv2D(256, kernel_size=(3, 3), padding='same', name='conv_c_3')(relu_c_2)\n",
    "    norm_c_3 = BatchNormalization(name='norm_c_3')(conv_c_3)\n",
    "    relu_c_3 = Activation('relu', name='relu_c_3')(norm_c_3)\n",
    " \n",
    "    # concate level level three and level four decomposition\n",
    "    concate_level_4 = concatenate([relu_3_2, relu_c_3])\n",
    "    conv_4 = Conv2D(256, kernel_size=(3, 3), padding='same', name='conv_4')(concate_level_4)\n",
    "    norm_4 = BatchNormalization(name='norm_4')(conv_4)\n",
    "    relu_4 = Activation('relu', name='relu_4')(norm_4)\n",
    " \n",
    "    conv_4_2 = Conv2D(256, kernel_size=(3, 3), strides=(2, 2), padding='same', name='conv_4_2')(relu_4)\n",
    "    norm_4_2 = BatchNormalization(name='norm_4_2')(conv_4_2)\n",
    "    relu_4_2 = Activation('relu', name='relu_4_2')(norm_4_2)\n",
    " \n",
    "    conv_5_1 = Conv2D(128, kernel_size=(3, 3), padding='same', name='conv_5_1')(relu_4_2)\n",
    "    norm_5_1 = BatchNormalization(name='norm_5_1')(conv_5_1)\n",
    "    relu_5_1 = Activation('relu', name='relu_5_1')(norm_5_1)\n",
    " \n",
    "    pool_5_1 = AveragePooling2D(pool_size=(7, 7), strides=1, padding='same', name='avg_pool_5_1')(relu_5_1)\n",
    "    #flat_5_1 = Flatten(name='flat_5_1')(pool_5_1) \n",
    " \n",
    "    #fc_5 = Dense(2048, name='fc_5')(flat_5_1)\n",
    "    #norm_5 = BatchNormalization(name='norm_5')(fc_5)\n",
    "    #relu_5 = Activation('relu', name='relu_5')(norm_5)\n",
    "    #drop_5 = Dropout(0.5, name='drop_5')(relu_5)\n",
    " \n",
    "    #fc_6 = Dense(2048, name='fc_6')(drop_5)\n",
    "    #norm_6 = BatchNormalization(name='norm_6')(fc_6)\n",
    "    #relu_6 = Activation('relu', name='relu_6')(norm_6)\n",
    "    #drop_6 = Dropout(0.5, name='drop_6')(relu_6)\n",
    "    flatten_layer = Flatten()(pool_5_1)\n",
    " \n",
    "    dense_layer1 = Dense(units=2048, activation='relu')(flatten_layer)\n",
    "    dense_layer1 = Dropout(0.4)(dense_layer1)\n",
    "    dense_layer2 = Dense(units=1024, activation='relu')(dense_layer1)\n",
    "    dense_layer2 = Dropout(0.4)(dense_layer2)\n",
    "    output_layer = Dense(units=output_units, activation='softmax')(dense_layer2)\n",
    " \n",
    "    model = Model(inputs=input_, outputs=output_layer)\n",
    "    model.summary()\n",
    "    plot_model(model, to_file='wavelet_cnn_0.5.png')\n",
    " \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 32872,
     "status": "ok",
     "timestamp": 1602478436734,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "iVgd4QmzgKKq",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "32d4779c-5699-49b0-eaef-613ac3ef7968",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "the_input (InputLayer)          [(None, 24, 24, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "wavelet (Lambda)                [(None, 12, 12, 12), 0           the_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv_1 (Conv2D)                 (None, 12, 12, 64)   6976        wavelet[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "norm_1 (BatchNormalization)     (None, 12, 12, 64)   256         conv_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu_1 (Activation)             (None, 12, 12, 64)   0           norm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_1_2 (Conv2D)               (None, 6, 6, 64)     36928       relu_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_a (Conv2D)                 (None, 6, 6, 64)     6976        wavelet[0][1]                    \n",
      "__________________________________________________________________________________________________\n",
      "norm_1_2 (BatchNormalization)   (None, 6, 6, 64)     256         conv_1_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "norm_a (BatchNormalization)     (None, 6, 6, 64)     256         conv_a[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu_1_2 (Activation)           (None, 6, 6, 64)     0           norm_1_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "relu_a (Activation)             (None, 6, 6, 64)     0           norm_a[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 6, 6, 128)    0           relu_1_2[0][0]                   \n",
      "                                                                 relu_a[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_2 (Conv2D)                 (None, 6, 6, 128)    147584      concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv_b (Conv2D)                 (None, 3, 3, 64)     6976        wavelet[0][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "norm_2 (BatchNormalization)     (None, 6, 6, 128)    512         conv_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "norm_b (BatchNormalization)     (None, 3, 3, 64)     256         conv_b[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu_2 (Activation)             (None, 6, 6, 128)    0           norm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu_b (Activation)             (None, 3, 3, 64)     0           norm_b[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_2_2 (Conv2D)               (None, 3, 3, 128)    147584      relu_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_b_2 (Conv2D)               (None, 3, 3, 128)    73856       relu_b[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "norm_2_2 (BatchNormalization)   (None, 3, 3, 128)    512         conv_2_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "norm_b_2 (BatchNormalization)   (None, 3, 3, 128)    512         conv_b_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_c (Conv2D)                 (None, 2, 2, 64)     6976        wavelet[0][3]                    \n",
      "__________________________________________________________________________________________________\n",
      "relu_2_2 (Activation)           (None, 3, 3, 128)    0           norm_2_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "relu_b_2 (Activation)           (None, 3, 3, 128)    0           norm_b_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "norm_c (BatchNormalization)     (None, 2, 2, 64)     256         conv_c[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 3, 3, 256)    0           relu_2_2[0][0]                   \n",
      "                                                                 relu_b_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "relu_c (Activation)             (None, 2, 2, 64)     0           norm_c[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_3 (Conv2D)                 (None, 3, 3, 256)    590080      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv_c_2 (Conv2D)               (None, 2, 2, 256)    147712      relu_c[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "nomr_3 (BatchNormalization)     (None, 3, 3, 256)    1024        conv_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "norm_c_2 (BatchNormalization)   (None, 2, 2, 256)    1024        conv_c_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "relu_3 (Activation)             (None, 3, 3, 256)    0           nomr_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu_c_2 (Activation)           (None, 2, 2, 256)    0           norm_c_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_3_2 (Conv2D)               (None, 2, 2, 256)    590080      relu_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_c_3 (Conv2D)               (None, 2, 2, 256)    590080      relu_c_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "norm_3_2 (BatchNormalization)   (None, 2, 2, 256)    1024        conv_3_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "norm_c_3 (BatchNormalization)   (None, 2, 2, 256)    1024        conv_c_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "relu_3_2 (Activation)           (None, 2, 2, 256)    0           norm_3_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "relu_c_3 (Activation)           (None, 2, 2, 256)    0           norm_c_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 2, 2, 512)    0           relu_3_2[0][0]                   \n",
      "                                                                 relu_c_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_4 (Conv2D)                 (None, 2, 2, 256)    1179904     concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "norm_4 (BatchNormalization)     (None, 2, 2, 256)    1024        conv_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu_4 (Activation)             (None, 2, 2, 256)    0           norm_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_4_2 (Conv2D)               (None, 1, 1, 256)    590080      relu_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "norm_4_2 (BatchNormalization)   (None, 1, 1, 256)    1024        conv_4_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "relu_4_2 (Activation)           (None, 1, 1, 256)    0           norm_4_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_5_1 (Conv2D)               (None, 1, 1, 128)    295040      relu_4_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "norm_5_1 (BatchNormalization)   (None, 1, 1, 128)    512         conv_5_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "relu_5_1 (Activation)           (None, 1, 1, 128)    0           norm_5_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool_5_1 (AveragePooling2D) (None, 1, 1, 128)    0           relu_5_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 128)          0           avg_pool_5_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 2048)         264192      flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 2048)         0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1024)         2098176     dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 1024)         0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 16)           16400       dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 6,805,072\n",
      "Trainable params: 6,800,336\n",
      "Non-trainable params: 4,736\n",
      "__________________________________________________________________________________________________\n",
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n"
     ]
    }
   ],
   "source": [
    "model = get_wavelet_cnn_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "executionInfo": {
     "elapsed": 32861,
     "status": "ok",
     "timestamp": 1602478436735,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "OYsuViCjhSA3"
   },
   "outputs": [],
   "source": [
    "#adam = Adam(lr=0.001, decay=1e-06)\n",
    "sgd = SGD(learning_rate=0.01, momentum=0.9, nesterov=False)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "executionInfo": {
     "elapsed": 32854,
     "status": "ok",
     "timestamp": 1602478436736,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "sUQZa9UD-rsL"
   },
   "outputs": [],
   "source": [
    "filepath = \"best-model.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='acc', verbose=1, save_best_only=False, mode='max')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 417831,
     "status": "ok",
     "timestamp": 1602478821720,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "OVwsWGf1hfg3",
    "outputId": "66ced090-c536-4f79-9bee-71ded4683b4d",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "181/181 [==============================] - 14s 37ms/step - loss: 0.6695 - accuracy: 0.7788\n",
      "\n",
      "Epoch 00001: saving model to best-model.hdf5\n",
      "Epoch 2/150\n",
      "181/181 [==============================] - 6s 34ms/step - loss: 0.1613 - accuracy: 0.9462\n",
      "\n",
      "Epoch 00002: saving model to best-model.hdf5\n",
      "Epoch 3/150\n",
      "181/181 [==============================] - 6s 34ms/step - loss: 0.1310 - accuracy: 0.9584\n",
      "\n",
      "Epoch 00003: saving model to best-model.hdf5\n",
      "Epoch 4/150\n",
      "181/181 [==============================] - 6s 34ms/step - loss: 0.1036 - accuracy: 0.9675\n",
      "\n",
      "Epoch 00004: saving model to best-model.hdf5\n",
      "Epoch 5/150\n",
      "181/181 [==============================] - 6s 34ms/step - loss: 0.0834 - accuracy: 0.9721\n",
      "\n",
      "Epoch 00005: saving model to best-model.hdf5\n",
      "Epoch 6/150\n",
      "181/181 [==============================] - 6s 34ms/step - loss: 0.0468 - accuracy: 0.9869\n",
      "\n",
      "Epoch 00006: saving model to best-model.hdf5\n",
      "Epoch 7/150\n",
      "181/181 [==============================] - 6s 34ms/step - loss: 0.0583 - accuracy: 0.9806\n",
      "\n",
      "Epoch 00007: saving model to best-model.hdf5\n",
      "Epoch 8/150\n",
      "181/181 [==============================] - 6s 34ms/step - loss: 0.0252 - accuracy: 0.9919 0s - loss: 0.0247 - accuracy: \n",
      "\n",
      "Epoch 00008: saving model to best-model.hdf5\n",
      "Epoch 9/150\n",
      "181/181 [==============================] - 6s 34ms/step - loss: 0.0270 - accuracy: 0.9908 0s - loss: 0.0257 \n",
      "\n",
      "Epoch 00009: saving model to best-model.hdf5\n",
      "Epoch 10/150\n",
      "181/181 [==============================] - 6s 34ms/step - loss: 0.0242 - accuracy: 0.9928 0s - loss: 0.0233 - accuracy: 0.\n",
      "\n",
      "Epoch 00010: saving model to best-model.hdf5\n",
      "Epoch 11/150\n",
      "181/181 [==============================] - 6s 34ms/step - loss: 0.0365 - accuracy: 0.9897\n",
      "\n",
      "Epoch 00011: saving model to best-model.hdf5\n",
      "Epoch 12/150\n",
      "181/181 [==============================] - 6s 34ms/step - loss: 0.0358 - accuracy: 0.9926\n",
      "\n",
      "Epoch 00012: saving model to best-model.hdf5\n",
      "Epoch 13/150\n",
      "181/181 [==============================] - 6s 34ms/step - loss: 0.0250 - accuracy: 0.9935\n",
      "\n",
      "Epoch 00013: saving model to best-model.hdf5\n",
      "Epoch 14/150\n",
      "181/181 [==============================] - 6s 35ms/step - loss: 0.0367 - accuracy: 0.9917\n",
      "\n",
      "Epoch 00014: saving model to best-model.hdf5\n",
      "Epoch 15/150\n",
      "181/181 [==============================] - 6s 34ms/step - loss: 0.0130 - accuracy: 0.9963 0s - loss: 0.012\n",
      "\n",
      "Epoch 00015: saving model to best-model.hdf5\n",
      "Epoch 16/150\n",
      "181/181 [==============================] - 6s 34ms/step - loss: 0.0205 - accuracy: 0.9950\n",
      "\n",
      "Epoch 00016: saving model to best-model.hdf5\n",
      "Epoch 17/150\n",
      "181/181 [==============================] - 6s 35ms/step - loss: 0.0187 - accuracy: 0.9945\n",
      "\n",
      "Epoch 00017: saving model to best-model.hdf5\n",
      "Epoch 18/150\n",
      "181/181 [==============================] - 6s 34ms/step - loss: 0.0111 - accuracy: 0.9965\n",
      "\n",
      "Epoch 00018: saving model to best-model.hdf5\n",
      "Epoch 19/150\n",
      "181/181 [==============================] - 6s 34ms/step - loss: 0.0275 - accuracy: 0.9915\n",
      "\n",
      "Epoch 00019: saving model to best-model.hdf5\n",
      "Epoch 20/150\n",
      "181/181 [==============================] - 6s 35ms/step - loss: 0.0097 - accuracy: 0.9970\n",
      "\n",
      "Epoch 00020: saving model to best-model.hdf5\n",
      "Epoch 21/150\n",
      "181/181 [==============================] - 6s 33ms/step - loss: 0.0101 - accuracy: 0.9963\n",
      "\n",
      "Epoch 00021: saving model to best-model.hdf5\n",
      "Epoch 22/150\n",
      "181/181 [==============================] - 6s 33ms/step - loss: 0.0100 - accuracy: 0.9967\n",
      "\n",
      "Epoch 00022: saving model to best-model.hdf5\n",
      "Epoch 23/150\n",
      "181/181 [==============================] - 6s 33ms/step - loss: 0.0321 - accuracy: 0.9915\n",
      "\n",
      "Epoch 00023: saving model to best-model.hdf5\n",
      "Epoch 24/150\n",
      "181/181 [==============================] - 6s 34ms/step - loss: 0.0071 - accuracy: 0.9978 0s - los\n",
      "\n",
      "Epoch 00024: saving model to best-model.hdf5\n",
      "Epoch 25/150\n",
      "181/181 [==============================] - 6s 33ms/step - loss: 0.0316 - accuracy: 0.9919\n",
      "\n",
      "Epoch 00025: saving model to best-model.hdf5\n",
      "Epoch 26/150\n",
      "181/181 [==============================] - 6s 34ms/step - loss: 0.0113 - accuracy: 0.9967\n",
      "\n",
      "Epoch 00026: saving model to best-model.hdf5\n",
      "Epoch 27/150\n",
      "181/181 [==============================] - 6s 33ms/step - loss: 0.0169 - accuracy: 0.9952\n",
      "\n",
      "Epoch 00027: saving model to best-model.hdf5\n",
      "Epoch 28/150\n",
      "181/181 [==============================] - 6s 33ms/step - loss: 0.0095 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00028: saving model to best-model.hdf5\n",
      "Epoch 29/150\n",
      "181/181 [==============================] - 6s 33ms/step - loss: 0.0139 - accuracy: 0.9954\n",
      "\n",
      "Epoch 00029: saving model to best-model.hdf5\n",
      "Epoch 30/150\n",
      "181/181 [==============================] - 6s 34ms/step - loss: 0.0132 - accuracy: 0.9952 0s - loss: 0.0143 \n",
      "\n",
      "Epoch 00030: saving model to best-model.hdf5\n",
      "Epoch 31/150\n",
      "181/181 [==============================] - 6s 33ms/step - loss: 0.0158 - accuracy: 0.9959\n",
      "\n",
      "Epoch 00031: saving model to best-model.hdf5\n",
      "Epoch 32/150\n",
      "181/181 [==============================] - 6s 33ms/step - loss: 0.0138 - accuracy: 0.9959 3s - loss: 0.020\n",
      "\n",
      "Epoch 00032: saving model to best-model.hdf5\n",
      "Epoch 33/150\n",
      "181/181 [==============================] - 6s 33ms/step - loss: 0.0043 - accuracy: 0.9989\n",
      "\n",
      "Epoch 00033: saving model to best-model.hdf5\n",
      "Epoch 34/150\n",
      "181/181 [==============================] - 6s 33ms/step - loss: 0.0182 - accuracy: 0.9948\n",
      "\n",
      "Epoch 00034: saving model to best-model.hdf5\n",
      "Epoch 35/150\n",
      "181/181 [==============================] - 6s 35ms/step - loss: 0.0081 - accuracy: 0.9978\n",
      "\n",
      "Epoch 00035: saving model to best-model.hdf5\n",
      "Epoch 36/150\n",
      "181/181 [==============================] - 6s 34ms/step - loss: 0.0018 - accuracy: 0.9996\n",
      "\n",
      "Epoch 00036: saving model to best-model.hdf5\n",
      "Epoch 37/150\n",
      "181/181 [==============================] - 6s 34ms/step - loss: 0.0046 - accuracy: 0.9993\n",
      "\n",
      "Epoch 00037: saving model to best-model.hdf5\n",
      "Epoch 38/150\n",
      "181/181 [==============================] - 6s 34ms/step - loss: 0.0188 - accuracy: 0.9956\n",
      "\n",
      "Epoch 00038: saving model to best-model.hdf5\n",
      "Epoch 39/150\n",
      "181/181 [==============================] - 6s 34ms/step - loss: 0.0112 - accuracy: 0.9974\n",
      "\n",
      "Epoch 00039: saving model to best-model.hdf5\n",
      "Epoch 40/150\n",
      "181/181 [==============================] - 6s 34ms/step - loss: 0.0096 - accuracy: 0.9967\n",
      "\n",
      "Epoch 00040: saving model to best-model.hdf5\n",
      "Epoch 41/150\n",
      "181/181 [==============================] - 6s 34ms/step - loss: 0.0032 - accuracy: 0.9993\n",
      "\n",
      "Epoch 00041: saving model to best-model.hdf5\n",
      "Epoch 42/150\n",
      "181/181 [==============================] - 6s 35ms/step - loss: 0.0125 - accuracy: 0.9965\n",
      "\n",
      "Epoch 00042: saving model to best-model.hdf5\n",
      "Epoch 43/150\n",
      "181/181 [==============================] - 6s 33ms/step - loss: 0.0050 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00043: saving model to best-model.hdf5\n",
      "Epoch 44/150\n",
      "181/181 [==============================] - 6s 34ms/step - loss: 0.0023 - accuracy: 0.9989 0s - loss: 0.001\n",
      "\n",
      "Epoch 00044: saving model to best-model.hdf5\n",
      "Epoch 45/150\n",
      "181/181 [==============================] - 7s 36ms/step - loss: 0.0044 - accuracy: 0.9989\n",
      "\n",
      "Epoch 00045: saving model to best-model.hdf5\n",
      "Epoch 46/150\n",
      "181/181 [==============================] - 6s 35ms/step - loss: 0.0234 - accuracy: 0.9926\n",
      "\n",
      "Epoch 00046: saving model to best-model.hdf5\n",
      "Epoch 47/150\n",
      "181/181 [==============================] - 7s 36ms/step - loss: 0.0114 - accuracy: 0.9969\n",
      "\n",
      "Epoch 00047: saving model to best-model.hdf5\n",
      "Epoch 48/150\n",
      "181/181 [==============================] - 6s 35ms/step - loss: 0.0062 - accuracy: 0.9993\n",
      "\n",
      "Epoch 00048: saving model to best-model.hdf5\n",
      "Epoch 49/150\n",
      "181/181 [==============================] - 6s 34ms/step - loss: 0.0026 - accuracy: 0.9991 0s - loss: 0.0028 - \n",
      "\n",
      "Epoch 00049: saving model to best-model.hdf5\n",
      "Epoch 50/150\n",
      "181/181 [==============================] - 6s 36ms/step - loss: 0.0029 - accuracy: 0.9989\n",
      "\n",
      "Epoch 00050: saving model to best-model.hdf5\n",
      "Epoch 51/150\n",
      "181/181 [==============================] - 6s 34ms/step - loss: 0.0016 - accuracy: 0.9996\n",
      "\n",
      "Epoch 00051: saving model to best-model.hdf5\n",
      "Epoch 52/150\n",
      "181/181 [==============================] - 6s 33ms/step - loss: 0.0022 - accuracy: 0.9994 1s - loss: 0.0 - ETA: 0s - loss: 0.0020 - ac\n",
      "\n",
      "Epoch 00052: saving model to best-model.hdf5\n",
      "Epoch 53/150\n",
      "181/181 [==============================] - 6s 34ms/step - loss: 0.0063 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00053: saving model to best-model.hdf5\n",
      "Epoch 54/150\n",
      "181/181 [==============================] - 6s 34ms/step - loss: 8.1479e-04 - accuracy: 0.9998\n",
      "\n",
      "Epoch 00054: saving model to best-model.hdf5\n",
      "Epoch 55/150\n",
      "181/181 [==============================] - 6s 36ms/step - loss: 7.1732e-04 - accuracy: 0.9996\n",
      "\n",
      "Epoch 00055: saving model to best-model.hdf5\n",
      "Epoch 56/150\n",
      "181/181 [==============================] - 7s 40ms/step - loss: 0.0094 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00056: saving model to best-model.hdf5\n",
      "Epoch 57/150\n",
      "181/181 [==============================] - 6s 33ms/step - loss: 0.0120 - accuracy: 0.9978\n",
      "\n",
      "Epoch 00057: saving model to best-model.hdf5\n",
      "Epoch 58/150\n",
      "181/181 [==============================] - 6s 33ms/step - loss: 0.0026 - accuracy: 0.9993\n",
      "\n",
      "Epoch 00058: saving model to best-model.hdf5\n",
      "Epoch 59/150\n",
      "181/181 [==============================] - 6s 33ms/step - loss: 0.0080 - accuracy: 0.9976\n",
      "\n",
      "Epoch 00059: saving model to best-model.hdf5\n",
      "Epoch 60/150\n",
      "181/181 [==============================] - 6s 34ms/step - loss: 0.0040 - accuracy: 0.9991 0s - loss: 0.0041 - accu\n",
      "\n",
      "Epoch 00060: saving model to best-model.hdf5\n",
      "Epoch 61/150\n",
      "181/181 [==============================] - 6s 33ms/step - loss: 0.0027 - accuracy: 0.9993\n",
      "\n",
      "Epoch 00061: saving model to best-model.hdf5\n",
      "Epoch 62/150\n",
      "181/181 [==============================] - 6s 33ms/step - loss: 0.0110 - accuracy: 0.9969\n",
      "\n",
      "Epoch 00062: saving model to best-model.hdf5\n",
      "Epoch 63/150\n",
      "181/181 [==============================] - 6s 34ms/step - loss: 0.0165 - accuracy: 0.9941\n",
      "\n",
      "Epoch 00063: saving model to best-model.hdf5\n",
      "Epoch 64/150\n",
      "181/181 [==============================] - 6s 33ms/step - loss: 0.0024 - accuracy: 0.9994\n",
      "\n",
      "Epoch 00064: saving model to best-model.hdf5\n",
      "Epoch 65/150\n",
      "181/181 [==============================] - 6s 34ms/step - loss: 0.0011 - accuracy: 0.9998\n",
      "\n",
      "Epoch 00065: saving model to best-model.hdf5\n",
      "Epoch 66/150\n",
      "181/181 [==============================] - 6s 33ms/step - loss: 0.0017 - accuracy: 0.9996\n",
      "\n",
      "Epoch 00066: saving model to best-model.hdf5\n",
      "Epoch 67/150\n",
      "181/181 [==============================] - 6s 33ms/step - loss: 0.0070 - accuracy: 0.9987\n",
      "\n",
      "Epoch 00067: saving model to best-model.hdf5\n",
      "Epoch 68/150\n",
      "181/181 [==============================] - 6s 33ms/step - loss: 0.0035 - accuracy: 0.9994\n",
      "\n",
      "Epoch 00068: saving model to best-model.hdf5\n",
      "Epoch 69/150\n",
      "181/181 [==============================] - 6s 33ms/step - loss: 6.2058e-04 - accuracy: 0.9998\n",
      "\n",
      "Epoch 00069: saving model to best-model.hdf5\n",
      "Epoch 70/150\n",
      "181/181 [==============================] - 6s 33ms/step - loss: 0.0050 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00070: saving model to best-model.hdf5\n",
      "Epoch 71/150\n",
      "181/181 [==============================] - 6s 34ms/step - loss: 0.0165 - accuracy: 0.9963\n",
      "\n",
      "Epoch 00071: saving model to best-model.hdf5\n",
      "Epoch 72/150\n",
      "181/181 [==============================] - 6s 34ms/step - loss: 0.0075 - accuracy: 0.9980\n",
      "\n",
      "Epoch 00072: saving model to best-model.hdf5\n",
      "Epoch 73/150\n",
      "181/181 [==============================] - 6s 33ms/step - loss: 0.0171 - accuracy: 0.9959\n",
      "\n",
      "Epoch 00073: saving model to best-model.hdf5\n",
      "Epoch 74/150\n",
      "181/181 [==============================] - 6s 33ms/step - loss: 0.0053 - accuracy: 0.9989\n",
      "\n",
      "Epoch 00074: saving model to best-model.hdf5\n",
      "Epoch 75/150\n",
      "181/181 [==============================] - 6s 35ms/step - loss: 0.0044 - accuracy: 0.9987\n",
      "\n",
      "Epoch 00075: saving model to best-model.hdf5\n",
      "Epoch 76/150\n",
      "181/181 [==============================] - 7s 36ms/step - loss: 0.0105 - accuracy: 0.9978\n",
      "\n",
      "Epoch 00076: saving model to best-model.hdf5\n",
      "Epoch 77/150\n",
      "181/181 [==============================] - 6s 35ms/step - loss: 0.0026 - accuracy: 0.9996\n",
      "\n",
      "Epoch 00077: saving model to best-model.hdf5\n",
      "Epoch 78/150\n",
      "181/181 [==============================] - 6s 34ms/step - loss: 4.0936e-04 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00078: saving model to best-model.hdf5\n",
      "Epoch 79/150\n",
      "181/181 [==============================] - 6s 34ms/step - loss: 4.0734e-04 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00079: saving model to best-model.hdf5\n",
      "Epoch 80/150\n",
      "181/181 [==============================] - 6s 35ms/step - loss: 8.9883e-04 - accuracy: 0.9998\n",
      "\n",
      "Epoch 00080: saving model to best-model.hdf5\n",
      "Epoch 81/150\n",
      "181/181 [==============================] - 6s 33ms/step - loss: 0.0087 - accuracy: 0.9974\n",
      "\n",
      "Epoch 00081: saving model to best-model.hdf5\n",
      "Epoch 82/150\n",
      "181/181 [==============================] - 6s 34ms/step - loss: 0.0098 - accuracy: 0.9972\n",
      "\n",
      "Epoch 00082: saving model to best-model.hdf5\n",
      "Epoch 83/150\n",
      "181/181 [==============================] - 6s 35ms/step - loss: 0.0019 - accuracy: 0.9994\n",
      "\n",
      "Epoch 00083: saving model to best-model.hdf5\n",
      "Epoch 84/150\n",
      "181/181 [==============================] - 7s 36ms/step - loss: 6.5858e-04 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00084: saving model to best-model.hdf5\n",
      "Epoch 85/150\n",
      "181/181 [==============================] - 6s 34ms/step - loss: 9.0937e-04 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00085: saving model to best-model.hdf5\n",
      "Epoch 86/150\n",
      "181/181 [==============================] - 6s 34ms/step - loss: 3.3417e-04 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00086: saving model to best-model.hdf5\n",
      "Epoch 87/150\n",
      "181/181 [==============================] - 6s 33ms/step - loss: 0.0082 - accuracy: 0.9970\n",
      "\n",
      "Epoch 00087: saving model to best-model.hdf5\n",
      "Epoch 88/150\n",
      "181/181 [==============================] - 6s 33ms/step - loss: 8.7731e-04 - accuracy: 0.9998\n",
      "\n",
      "Epoch 00088: saving model to best-model.hdf5\n",
      "Epoch 89/150\n",
      "181/181 [==============================] - 6s 33ms/step - loss: 5.0778e-04 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00089: saving model to best-model.hdf5\n",
      "Epoch 90/150\n",
      "181/181 [==============================] - 6s 33ms/step - loss: 0.0016 - accuracy: 0.9996\n",
      "\n",
      "Epoch 00090: saving model to best-model.hdf5\n",
      "Epoch 91/150\n",
      "181/181 [==============================] - 6s 33ms/step - loss: 0.0020 - accuracy: 0.9994\n",
      "\n",
      "Epoch 00091: saving model to best-model.hdf5\n",
      "Epoch 92/150\n",
      "181/181 [==============================] - 6s 33ms/step - loss: 0.0075 - accuracy: 0.9976\n",
      "\n",
      "Epoch 00092: saving model to best-model.hdf5\n",
      "Epoch 93/150\n",
      "181/181 [==============================] - 6s 33ms/step - loss: 0.0043 - accuracy: 0.9993\n",
      "\n",
      "Epoch 00093: saving model to best-model.hdf5\n",
      "Epoch 94/150\n",
      "181/181 [==============================] - 6s 34ms/step - loss: 2.5734e-04 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00094: saving model to best-model.hdf5\n",
      "Epoch 95/150\n",
      "181/181 [==============================] - 7s 36ms/step - loss: 0.0021 - accuracy: 0.9993\n",
      "\n",
      "Epoch 00095: saving model to best-model.hdf5\n",
      "Epoch 96/150\n",
      "181/181 [==============================] - 7s 36ms/step - loss: 0.0051 - accuracy: 0.9989\n",
      "\n",
      "Epoch 00096: saving model to best-model.hdf5\n",
      "Epoch 97/150\n",
      "181/181 [==============================] - 6s 34ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00097: saving model to best-model.hdf5\n",
      "Epoch 98/150\n",
      "181/181 [==============================] - 6s 34ms/step - loss: 4.8454e-04 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00098: saving model to best-model.hdf5\n",
      "Epoch 99/150\n",
      "181/181 [==============================] - 6s 34ms/step - loss: 0.0022 - accuracy: 0.9996ETA: 0s - loss: 2.7966e-04 - accuracy\n",
      "\n",
      "Epoch 00099: saving model to best-model.hdf5\n",
      "Epoch 100/150\n",
      "181/181 [==============================] - 6s 34ms/step - loss: 0.0065 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00100: saving model to best-model.hdf5\n",
      "Epoch 101/150\n",
      "181/181 [==============================] - 6s 35ms/step - loss: 0.0063 - accuracy: 0.9978\n",
      "\n",
      "Epoch 00101: saving model to best-model.hdf5\n",
      "Epoch 102/150\n",
      "181/181 [==============================] - 6s 34ms/step - loss: 0.0040 - accuracy: 0.9989\n",
      "\n",
      "Epoch 00102: saving model to best-model.hdf5\n",
      "Epoch 103/150\n",
      "181/181 [==============================] - 6s 34ms/step - loss: 4.3635e-04 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00103: saving model to best-model.hdf5\n",
      "Epoch 104/150\n",
      "181/181 [==============================] - 6s 34ms/step - loss: 2.1753e-04 - accuracy: 1.0000 1s - l\n",
      "\n",
      "Epoch 00104: saving model to best-model.hdf5\n",
      "Epoch 105/150\n",
      "181/181 [==============================] - 6s 34ms/step - loss: 5.1594e-04 - accuracy: 1.0000 0s - loss: 4.8834e-04 \n",
      "\n",
      "Epoch 00105: saving model to best-model.hdf5\n",
      "Epoch 106/150\n",
      "181/181 [==============================] - 6s 36ms/step - loss: 6.9739e-04 - accuracy: 0.9996\n",
      "\n",
      "Epoch 00106: saving model to best-model.hdf5\n",
      "Epoch 107/150\n",
      "181/181 [==============================] - 6s 35ms/step - loss: 0.0047 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00107: saving model to best-model.hdf5\n",
      "Epoch 108/150\n",
      "181/181 [==============================] - 6s 35ms/step - loss: 0.0040 - accuracy: 0.9993\n",
      "\n",
      "Epoch 00108: saving model to best-model.hdf5\n",
      "Epoch 109/150\n",
      "181/181 [==============================] - 6s 34ms/step - loss: 0.0033 - accuracy: 0.9994\n",
      "\n",
      "Epoch 00109: saving model to best-model.hdf5\n",
      "Epoch 110/150\n",
      "181/181 [==============================] - 6s 35ms/step - loss: 0.0022 - accuracy: 0.9987\n",
      "\n",
      "Epoch 00110: saving model to best-model.hdf5\n",
      "Epoch 111/150\n",
      "181/181 [==============================] - 6s 34ms/step - loss: 2.7205e-04 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00111: saving model to best-model.hdf5\n",
      "Epoch 112/150\n",
      "181/181 [==============================] - 6s 34ms/step - loss: 1.4300e-04 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00112: saving model to best-model.hdf5\n",
      "Epoch 113/150\n",
      "181/181 [==============================] - 6s 35ms/step - loss: 0.0012 - accuracy: 0.9996\n",
      "\n",
      "Epoch 00113: saving model to best-model.hdf5\n",
      "Epoch 114/150\n",
      "181/181 [==============================] - 6s 34ms/step - loss: 3.7892e-04 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00114: saving model to best-model.hdf5\n",
      "Epoch 115/150\n",
      "181/181 [==============================] - 6s 35ms/step - loss: 1.6588e-04 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00115: saving model to best-model.hdf5\n",
      "Epoch 116/150\n",
      "181/181 [==============================] - 6s 36ms/step - loss: 0.0026 - accuracy: 0.9991\n",
      "\n",
      "Epoch 00116: saving model to best-model.hdf5\n",
      "Epoch 117/150\n",
      "181/181 [==============================] - 6s 34ms/step - loss: 2.3917e-04 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00117: saving model to best-model.hdf5\n",
      "Epoch 118/150\n",
      "181/181 [==============================] - 6s 35ms/step - loss: 0.0014 - accuracy: 0.9996\n",
      "\n",
      "Epoch 00118: saving model to best-model.hdf5\n",
      "Epoch 119/150\n",
      "181/181 [==============================] - 6s 34ms/step - loss: 0.0073 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00119: saving model to best-model.hdf5\n",
      "Epoch 120/150\n",
      "181/181 [==============================] - 6s 35ms/step - loss: 0.0069 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00120: saving model to best-model.hdf5\n",
      "Epoch 121/150\n",
      "181/181 [==============================] - 6s 34ms/step - loss: 3.3510e-04 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00121: saving model to best-model.hdf5\n",
      "Epoch 122/150\n",
      "181/181 [==============================] - 6s 35ms/step - loss: 5.2997e-04 - accuracy: 0.9998\n",
      "\n",
      "Epoch 00122: saving model to best-model.hdf5\n",
      "Epoch 123/150\n",
      "181/181 [==============================] - 6s 34ms/step - loss: 0.0015 - accuracy: 0.9994\n",
      "\n",
      "Epoch 00123: saving model to best-model.hdf5\n",
      "Epoch 124/150\n",
      "181/181 [==============================] - 6s 35ms/step - loss: 3.0033e-04 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00124: saving model to best-model.hdf5\n",
      "Epoch 125/150\n",
      "181/181 [==============================] - 6s 34ms/step - loss: 1.6083e-04 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00125: saving model to best-model.hdf5\n",
      "Epoch 126/150\n",
      "181/181 [==============================] - 6s 36ms/step - loss: 0.0066 - accuracy: 0.9987\n",
      "\n",
      "Epoch 00126: saving model to best-model.hdf5\n",
      "Epoch 127/150\n",
      "181/181 [==============================] - 7s 37ms/step - loss: 2.3727e-04 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00127: saving model to best-model.hdf5\n",
      "Epoch 128/150\n",
      "181/181 [==============================] - 6s 36ms/step - loss: 7.8866e-04 - accuracy: 0.9996\n",
      "\n",
      "Epoch 00128: saving model to best-model.hdf5\n",
      "Epoch 129/150\n",
      "181/181 [==============================] - 6s 36ms/step - loss: 4.1144e-04 - accuracy: 0.9998\n",
      "\n",
      "Epoch 00129: saving model to best-model.hdf5\n",
      "Epoch 130/150\n",
      "181/181 [==============================] - 6s 35ms/step - loss: 3.5073e-04 - accuracy: 0.9998\n",
      "\n",
      "Epoch 00130: saving model to best-model.hdf5\n",
      "Epoch 131/150\n",
      "181/181 [==============================] - 6s 33ms/step - loss: 1.4459e-04 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00131: saving model to best-model.hdf5\n",
      "Epoch 132/150\n",
      "181/181 [==============================] - 6s 33ms/step - loss: 0.0130 - accuracy: 0.9956\n",
      "\n",
      "Epoch 00132: saving model to best-model.hdf5\n",
      "Epoch 133/150\n",
      "181/181 [==============================] - 6s 33ms/step - loss: 0.0116 - accuracy: 0.9978\n",
      "\n",
      "Epoch 00133: saving model to best-model.hdf5\n",
      "Epoch 134/150\n",
      "181/181 [==============================] - 6s 34ms/step - loss: 0.0023 - accuracy: 0.9993 0s - l\n",
      "\n",
      "Epoch 00134: saving model to best-model.hdf5\n",
      "Epoch 135/150\n",
      "181/181 [==============================] - 6s 36ms/step - loss: 0.0029 - accuracy: 0.9991 0s - loss: 0.0031 - accu\n",
      "\n",
      "Epoch 00135: saving model to best-model.hdf5\n",
      "Epoch 136/150\n",
      "181/181 [==============================] - 6s 35ms/step - loss: 0.0170 - accuracy: 0.9950\n",
      "\n",
      "Epoch 00136: saving model to best-model.hdf5\n",
      "Epoch 137/150\n",
      "181/181 [==============================] - 6s 35ms/step - loss: 0.0058 - accuracy: 0.9989\n",
      "\n",
      "Epoch 00137: saving model to best-model.hdf5\n",
      "Epoch 138/150\n",
      "181/181 [==============================] - 6s 35ms/step - loss: 0.0029 - accuracy: 0.9991\n",
      "\n",
      "Epoch 00138: saving model to best-model.hdf5\n",
      "Epoch 139/150\n",
      "181/181 [==============================] - 6s 35ms/step - loss: 0.0027 - accuracy: 0.9993\n",
      "\n",
      "Epoch 00139: saving model to best-model.hdf5\n",
      "Epoch 140/150\n",
      "181/181 [==============================] - 6s 35ms/step - loss: 0.0025 - accuracy: 0.9996\n",
      "\n",
      "Epoch 00140: saving model to best-model.hdf5\n",
      "Epoch 141/150\n",
      "181/181 [==============================] - 6s 34ms/step - loss: 0.0083 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00141: saving model to best-model.hdf5\n",
      "Epoch 142/150\n",
      "181/181 [==============================] - 6s 36ms/step - loss: 0.0258 - accuracy: 0.9924\n",
      "\n",
      "Epoch 00142: saving model to best-model.hdf5\n",
      "Epoch 143/150\n",
      "181/181 [==============================] - 6s 34ms/step - loss: 0.0057 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00143: saving model to best-model.hdf5\n",
      "Epoch 144/150\n",
      "181/181 [==============================] - 6s 34ms/step - loss: 0.0030 - accuracy: 0.9991\n",
      "\n",
      "Epoch 00144: saving model to best-model.hdf5\n",
      "Epoch 145/150\n",
      "181/181 [==============================] - 6s 35ms/step - loss: 0.0039 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00145: saving model to best-model.hdf5\n",
      "Epoch 146/150\n",
      "181/181 [==============================] - 6s 34ms/step - loss: 6.9204e-04 - accuracy: 0.9998\n",
      "\n",
      "Epoch 00146: saving model to best-model.hdf5\n",
      "Epoch 147/150\n",
      "181/181 [==============================] - 7s 38ms/step - loss: 0.0013 - accuracy: 0.9996\n",
      "\n",
      "Epoch 00147: saving model to best-model.hdf5\n",
      "Epoch 148/150\n",
      "181/181 [==============================] - 6s 35ms/step - loss: 0.0031 - accuracy: 0.9994\n",
      "\n",
      "Epoch 00148: saving model to best-model.hdf5\n",
      "Epoch 149/150\n",
      "181/181 [==============================] - 7s 36ms/step - loss: 0.0029 - accuracy: 0.9993\n",
      "\n",
      "Epoch 00149: saving model to best-model.hdf5\n",
      "Epoch 150/150\n",
      "181/181 [==============================] - 6s 35ms/step - loss: 0.0017 - accuracy: 0.9998\n",
      "\n",
      "Epoch 00150: saving model to best-model.hdf5\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=Xtrain, y=ytrain, batch_size = 30, epochs=150, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R5-BLNivkkD2"
   },
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 445
    },
    "executionInfo": {
     "elapsed": 417824,
     "status": "ok",
     "timestamp": 1602478821723,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "rzi0kGwckZIh",
    "outputId": "860ced41-4c23-4c7b-d0d9-88b35f1d005f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1d9e508fc70>]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(7,7)) \n",
    "plt.grid() \n",
    "plt.plot(history.history['loss'])\n",
    "#plt.plot(history.history['val_loss'])\n",
    "#plt.ylabel('Loss') \n",
    "#plt.xlabel('Epochs') \n",
    "#plt.legend(['Training','Validation'], loc='upper right') \n",
    "#plt.savefig(\"loss_curve.pdf\") \n",
    "#plt.show()\n",
    "#plt.figure(figsize=(5,5)) \n",
    "#plt.ylim(0,1.1) \n",
    "#plt.grid() \n",
    "#plt.plot(history.history['acc'])\n",
    "#plt.plot(history.history['val_acc'])\n",
    "#plt.ylabel('Accuracy') \n",
    "#plt.xlabel('Epochs') \n",
    "#plt.legend(['Training','Validation']) \n",
    "#plt.savefig(\"acc_curve.pdf\") \n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "executionInfo": {
     "elapsed": 418307,
     "status": "ok",
     "timestamp": 1602478822219,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "HKSPxOqckkD3"
   },
   "outputs": [],
   "source": [
    "# load best weights\n",
    "model.load_weights(\"best-model.hdf5\")\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 418301,
     "status": "ok",
     "timestamp": 1602478822220,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "tzGuqZILkkD5",
    "outputId": "58b28fd2-e2a8-47a5-94bd-3bb222491aa0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48717, 24, 24, 3, 1)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtest = Xtest.reshape(-1, windowSize, windowSize, K, 1)\n",
    "Xtest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 418293,
     "status": "ok",
     "timestamp": 1602478822221,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "FIhcrDHQkkD7",
    "outputId": "301bc50b-063d-4ad4-b84e-96658ec5bfee"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48717, 16)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytest = np_utils.to_categorical(ytest)\n",
    "ytest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 403
    },
    "executionInfo": {
     "elapsed": 427183,
     "status": "ok",
     "timestamp": 1602478831122,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "x9gnEB8wkkD-",
    "outputId": "38e44cce-3f72-40f7-b8e4-5914a2294f69"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1808\n",
      "           1       1.00      1.00      1.00      3354\n",
      "           2       1.00      1.00      1.00      1779\n",
      "           3       1.00      1.00      1.00      1255\n",
      "           4       1.00      1.00      1.00      2410\n",
      "           5       1.00      1.00      1.00      3563\n",
      "           6       1.00      1.00      1.00      3221\n",
      "           7       1.00      1.00      1.00     10144\n",
      "           8       1.00      1.00      1.00      5583\n",
      "           9       1.00      1.00      1.00      2950\n",
      "          10       1.00      0.99      1.00       961\n",
      "          11       1.00      1.00      1.00      1734\n",
      "          12       1.00      1.00      1.00       825\n",
      "          13       1.00      1.00      1.00       963\n",
      "          14       0.99      1.00      1.00      6541\n",
      "          15       1.00      1.00      1.00      1626\n",
      "\n",
      "    accuracy                           1.00     48717\n",
      "   macro avg       1.00      1.00      1.00     48717\n",
      "weighted avg       1.00      1.00      1.00     48717\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y_pred_test = model.predict(Xtest)\n",
    "y_pred_test = np.argmax(Y_pred_test, axis=1)\n",
    " \n",
    "classification = classification_report(np.argmax(ytest, axis=1), y_pred_test)\n",
    "print(classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "executionInfo": {
     "elapsed": 427171,
     "status": "ok",
     "timestamp": 1602478831123,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "M8Z-62eCkkEA"
   },
   "outputs": [],
   "source": [
    "def AA_andEachClassAccuracy(confusion_matrix):\n",
    "    counter = confusion_matrix.shape[0]\n",
    "    list_diag = np.diag(confusion_matrix)\n",
    "    list_raw_sum = np.sum(confusion_matrix, axis=1)\n",
    "    each_acc = np.nan_to_num(truediv(list_diag, list_raw_sum))\n",
    "    average_acc = np.mean(each_acc)\n",
    "    return each_acc, average_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "executionInfo": {
     "elapsed": 427165,
     "status": "ok",
     "timestamp": 1602478831124,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "Jw2j7mjQkkEC"
   },
   "outputs": [],
   "source": [
    "def reports (X_test,y_test,name):\n",
    "    #start = time.time()\n",
    "    Y_pred = model.predict(X_test)\n",
    "    y_pred = np.argmax(Y_pred, axis=1)\n",
    "    #end = time.time()\n",
    "    #print(end - start)\n",
    "    if name == 'IP':\n",
    "        target_names = ['Alfalfa', 'Corn-notill', 'Corn-mintill', 'Corn'\n",
    "                        ,'Grass-pasture', 'Grass-trees', 'Grass-pasture-mowed', \n",
    "                        'Hay-windrowed', 'Oats', 'Soybean-notill', 'Soybean-mintill',\n",
    "                        'Soybean-clean', 'Wheat', 'Woods', 'Buildings-Grass-Trees-Drives',\n",
    "                        'Stone-Steel-Towers']\n",
    "    elif name == 'SA':\n",
    "        target_names = ['Brocoli_green_weeds_1','Brocoli_green_weeds_2','Fallow','Fallow_rough_plow','Fallow_smooth',\n",
    "                        'Stubble','Celery','Grapes_untrained','Soil_vinyard_develop','Corn_senesced_green_weeds',\n",
    "                        'Lettuce_romaine_4wk','Lettuce_romaine_5wk','Lettuce_romaine_6wk','Lettuce_romaine_7wk',\n",
    "                        'Vinyard_untrained','Vinyard_vertical_trellis']\n",
    "    elif name == 'PU':\n",
    "        target_names = ['Asphalt','Meadows','Gravel','Trees', 'Painted metal sheets','Bare Soil','Bitumen',\n",
    "                        'Self-Blocking Bricks','Shadows']\n",
    "    \n",
    "    classification = classification_report(np.argmax(y_test, axis=1), y_pred, target_names=target_names)\n",
    "    oa = accuracy_score(np.argmax(y_test, axis=1), y_pred)\n",
    "    confusion = confusion_matrix(np.argmax(y_test, axis=1), y_pred)\n",
    "    each_acc, aa = AA_andEachClassAccuracy(confusion)\n",
    "    kappa = cohen_kappa_score(np.argmax(y_test, axis=1), y_pred)\n",
    "    score = model.evaluate(X_test, y_test, batch_size=32)\n",
    "    Test_Loss =  score[0]*100\n",
    "    Test_accuracy = score[1]*100\n",
    "    \n",
    "    return classification, confusion, Test_Loss, Test_accuracy, oa*100, each_acc*100, aa*100, kappa*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 445851,
     "status": "ok",
     "timestamp": 1602478849818,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "wiez8wEtkkEE",
    "outputId": "9955427d-ee60-4060-b1eb-9e79bbf5b67f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1523/1523 [==============================] - 29s 18ms/step - loss: 0.0042 - accuracy: 0.9988\n"
     ]
    }
   ],
   "source": [
    "classification, confusion, Test_loss, Test_accuracy, oa, each_acc, aa, kappa = reports(Xtest,ytest,dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "executionInfo": {
     "elapsed": 445840,
     "status": "ok",
     "timestamp": 1602478849819,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "kR-idaI8J5bl"
   },
   "outputs": [],
   "source": [
    "classification = str(classification)\n",
    "confusion = str(confusion)\n",
    "file_name = \"classification_report.txt\"\n",
    "\n",
    "with open(file_name, 'w') as x_file:\n",
    "    x_file.write('{} Test loss (%)'.format(Test_loss))\n",
    "    x_file.write('\\n')\n",
    "    x_file.write('{} Test accuracy (%)'.format(Test_accuracy))\n",
    "    x_file.write('\\n')\n",
    "    x_file.write('\\n')\n",
    "    x_file.write('{} Kappa accuracy (%)'.format(kappa))\n",
    "    x_file.write('\\n')\n",
    "    x_file.write('{} Overall accuracy (%)'.format(oa))\n",
    "    x_file.write('\\n')\n",
    "    x_file.write('{} Average accuracy (%)'.format(aa))\n",
    "    x_file.write('\\n')\n",
    "    x_file.write('\\n')\n",
    "    x_file.write('{}'.format(classification))\n",
    "    x_file.write('\\n')\n",
    "    x_file.write('{}'.format(confusion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "executionInfo": {
     "elapsed": 445833,
     "status": "ok",
     "timestamp": 1602478849820,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "xGcIixswkkEG"
   },
   "outputs": [],
   "source": [
    "def Patch(data,height_index,width_index):\n",
    "    height_slice = slice(height_index, height_index+PATCH_SIZE)\n",
    "    width_slice = slice(width_index, width_index+PATCH_SIZE)\n",
    "    patch = data[height_slice, width_slice, :]\n",
    "    \n",
    "    return patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "executionInfo": {
     "elapsed": 445826,
     "status": "ok",
     "timestamp": 1602478849821,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "r-HdxMrCkkEJ"
   },
   "outputs": [],
   "source": [
    "# load the original image\n",
    "X, y = loadData(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "executionInfo": {
     "elapsed": 445812,
     "status": "ok",
     "timestamp": 1602478849821,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "6GaaBm4BkkEL"
   },
   "outputs": [],
   "source": [
    "height = y.shape[0]\n",
    "width = y.shape[1]\n",
    "PATCH_SIZE = windowSize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "executionInfo": {
     "elapsed": 470026,
     "status": "ok",
     "timestamp": 1602478874044,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "oumhazm3kkEN"
   },
   "outputs": [],
   "source": [
    "K = 3\n",
    "X,fa = applyFA(X, numComponents=K)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "executionInfo": {
     "elapsed": 470018,
     "status": "ok",
     "timestamp": 1602478874046,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "tvZuH_0-kkEP"
   },
   "outputs": [],
   "source": [
    "X = padWithZeros(X, PATCH_SIZE//2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "4sHtc-12kkER"
   },
   "outputs": [],
   "source": [
    "# calculate the predicted image\n",
    "outputs = np.zeros((height,width))\n",
    "for i in range(height):\n",
    "    for j in range(width):\n",
    "        target = int(y[i,j])\n",
    "        if target == 0 :\n",
    "            continue\n",
    "        else :\n",
    "            image_patch=Patch(X,i,j)\n",
    "            X_test_image = image_patch.reshape(1,image_patch.shape[0],image_patch.shape[1], image_patch.shape[2], 1).astype('float32')                                   \n",
    "            prediction = (model.predict(X_test_image))\n",
    "            prediction = np.argmax(prediction, axis=1)\n",
    "            outputs[i][j] = prediction+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "KpnGO-c_kkET"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ground_truth = spectral.imshow(classes = y,figsize =(7,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "5yIVQ8-hkkEW"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "predict_image = spectral.imshow(classes = outputs.astype(int),figsize =(7,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "vBPvnosekkEZ"
   },
   "outputs": [],
   "source": [
    "spectral.save_rgb(\"predictions.jpg\", outputs.astype(int), colors=spectral.spy_colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "the_input (InputLayer)          [(None, 24, 24, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "wavelet (Lambda)                [(None, 12, 12, 12), 0           the_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv_1 (Conv2D)                 (None, 12, 12, 64)   6976        wavelet[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "norm_1 (BatchNormalization)     (None, 12, 12, 64)   256         conv_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu_1 (Activation)             (None, 12, 12, 64)   0           norm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_1_2 (Conv2D)               (None, 6, 6, 64)     36928       relu_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_a (Conv2D)                 (None, 6, 6, 64)     6976        wavelet[0][1]                    \n",
      "__________________________________________________________________________________________________\n",
      "norm_1_2 (BatchNormalization)   (None, 6, 6, 64)     256         conv_1_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "norm_a (BatchNormalization)     (None, 6, 6, 64)     256         conv_a[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu_1_2 (Activation)           (None, 6, 6, 64)     0           norm_1_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "relu_a (Activation)             (None, 6, 6, 64)     0           norm_a[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 6, 6, 128)    0           relu_1_2[0][0]                   \n",
      "                                                                 relu_a[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_2 (Conv2D)                 (None, 6, 6, 128)    147584      concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv_b (Conv2D)                 (None, 3, 3, 64)     6976        wavelet[0][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "norm_2 (BatchNormalization)     (None, 6, 6, 128)    512         conv_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "norm_b (BatchNormalization)     (None, 3, 3, 64)     256         conv_b[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu_2 (Activation)             (None, 6, 6, 128)    0           norm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu_b (Activation)             (None, 3, 3, 64)     0           norm_b[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_2_2 (Conv2D)               (None, 3, 3, 128)    147584      relu_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_b_2 (Conv2D)               (None, 3, 3, 128)    73856       relu_b[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "norm_2_2 (BatchNormalization)   (None, 3, 3, 128)    512         conv_2_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "norm_b_2 (BatchNormalization)   (None, 3, 3, 128)    512         conv_b_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_c (Conv2D)                 (None, 2, 2, 64)     6976        wavelet[0][3]                    \n",
      "__________________________________________________________________________________________________\n",
      "relu_2_2 (Activation)           (None, 3, 3, 128)    0           norm_2_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "relu_b_2 (Activation)           (None, 3, 3, 128)    0           norm_b_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "norm_c (BatchNormalization)     (None, 2, 2, 64)     256         conv_c[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 3, 3, 256)    0           relu_2_2[0][0]                   \n",
      "                                                                 relu_b_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "relu_c (Activation)             (None, 2, 2, 64)     0           norm_c[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_3 (Conv2D)                 (None, 3, 3, 256)    590080      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv_c_2 (Conv2D)               (None, 2, 2, 256)    147712      relu_c[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "nomr_3 (BatchNormalization)     (None, 3, 3, 256)    1024        conv_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "norm_c_2 (BatchNormalization)   (None, 2, 2, 256)    1024        conv_c_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "relu_3 (Activation)             (None, 3, 3, 256)    0           nomr_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu_c_2 (Activation)           (None, 2, 2, 256)    0           norm_c_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_3_2 (Conv2D)               (None, 2, 2, 256)    590080      relu_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_c_3 (Conv2D)               (None, 2, 2, 256)    590080      relu_c_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "norm_3_2 (BatchNormalization)   (None, 2, 2, 256)    1024        conv_3_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "norm_c_3 (BatchNormalization)   (None, 2, 2, 256)    1024        conv_c_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "relu_3_2 (Activation)           (None, 2, 2, 256)    0           norm_3_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "relu_c_3 (Activation)           (None, 2, 2, 256)    0           norm_c_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 2, 2, 512)    0           relu_3_2[0][0]                   \n",
      "                                                                 relu_c_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_4 (Conv2D)                 (None, 2, 2, 256)    1179904     concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "norm_4 (BatchNormalization)     (None, 2, 2, 256)    1024        conv_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu_4 (Activation)             (None, 2, 2, 256)    0           norm_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_4_2 (Conv2D)               (None, 1, 1, 256)    590080      relu_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "norm_4_2 (BatchNormalization)   (None, 1, 1, 256)    1024        conv_4_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "relu_4_2 (Activation)           (None, 1, 1, 256)    0           norm_4_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_5_1 (Conv2D)               (None, 1, 1, 128)    295040      relu_4_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "norm_5_1 (BatchNormalization)   (None, 1, 1, 128)    512         conv_5_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "relu_5_1 (Activation)           (None, 1, 1, 128)    0           norm_5_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool_5_1 (AveragePooling2D) (None, 1, 1, 128)    0           relu_5_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 128)          0           avg_pool_5_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 2048)         264192      flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 2048)         0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1024)         2098176     dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 1024)         0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 16)           16400       dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 6,805,072\n",
      "Trainable params: 6,800,336\n",
      "Non-trainable params: 4,736\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JL4rV6j7kkEa"
   },
   "source": [
    "spectral.save_rgb(str(dataset)+\"_ground_truth.jpg\", y, colors=spectral.spy_colors)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyN/aVtrq8w9XQ9tKxeZX/5h",
   "collapsed_sections": [],
   "name": "Untitled1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
